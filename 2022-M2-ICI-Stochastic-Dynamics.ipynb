{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical exercices - M2 ICI 2021 (Guillaume Stirnemann)\n",
    "\n",
    "Here, we will illustrate some of the class' concepts about stochastic dynamics in biomolecular systems. The present notebook can be executed using Jupyter. You don't need to know Python beforehands, and you should be able to quickly grasp some simple Python vocabulary. \n",
    "\n",
    "We first need to load some libraries. These are suites of functions that were already implemented and widely distributed so that everyone can use them. Here, this includes some very convenient and common libraries for numerical calculations (numpy) or plotting libraries (matplotlib). \n",
    "\n",
    "To execute a cell, press Shift + Enter at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Depolymerization of actin  \n",
    "\n",
    "Actin is a key constituent of the cytoskeleton, which allows a cell to perform many of its functions, to maintain its shape, and to move. In vivo, actin monomers polymerize to form long filaments that are about 16 $\\mu$m long on average. It possesses a directional character: at the (-) end, it binds actin monomers linked to ADP; at the (+) end, it binds actin monomers linked to ATP. Each monomer is about 4-nm long. \n",
    "\n",
    "Below, you are provided with a code that can perform stochastic simulations of coin flipping. Given a probability $p$ to have heads, it returns the number of heads obtained for a given number number of trials $n$, and repeated $size$ times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_coinflips(n, p, size=1):\n",
    "    \"\"\"\n",
    "    Simulate n_samples sets of n coin flips with prob. p of heads.\n",
    "    \"\"\"\n",
    "    n_heads = np.empty(size, dtype=int)\n",
    "    for i in range(size):\n",
    "        n_heads[i] = np.sum(np.random.random(size=n) < p)\n",
    "    return n_heads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is an example of a real coin-tossing experiments. Let's make 25 trials and repeat the experiment 10 times. $theor\\_dist$ returns the expectations of $P(k,n)$, i.e., the probability to obtain $k$ heads among $n$ trials. It is basically the exact version of the Poisson formula we have seen in the class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \n",
    "p = \n",
    "h_plot = np.arange(n+1)\n",
    "theor_dist = st.binom.pmf(h_plot, n, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=\n",
    "mu=n*p\n",
    "h = simulate_coinflips(n, p, size)\n",
    "plt.plot(h_plot, theor_dist,color='blue',marker='o',label='expected',linestyle='')\n",
    "plt.plot(np.arange(h.max()+1), np.bincount(h)/size, color='orange',marker='o',label='P(h)',linestyle='')\n",
    "plt.plot(h_plot, poisson.pmf(h_plot,mu),color='red',marker='o',label='expected',linestyle='')\n",
    "\n",
    "plt.xlabel('Number of heads n')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Now, execute the previous cell several times. What is happening? Why?\n",
    "\n",
    "(2) Increase your sample size and try to judge how many samples would be required so that the obtained statistics follows the expectations. \n",
    "\n",
    "(3) Let's go back to the original problem of actin. We wonder how many depolymerization events we can observe during a time window of 10 seconds. The time resolution of your experiment is 100 ms. The depolymerization rate at the (+) end is 3.3 s$^{-1}$. We will assume no depolymerization on the (-) end. By adapting the above code, how many times to you need to repeat the experiment to obtain a reliable Poisson distribution? \n",
    "\n",
    "The Poisson distribution function is already present in Python as well. It is accessible using $poisson.pmf(k,\\mu)$, which returns the probability of having $k$ events of probability $p$, out of $n$ realizations, with $\\mu=p\\times n$. to plot the Poisson distribution, you can add the following line when you are doing your figure: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(h_plot, poisson.pmf(h_plot,mu),color='red',marker='o',label='expected',linestyle='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Compare the Poisson distribution and the binomial distribution expectation. Comment on the possible differences. \n",
    "\n",
    "[Bonus question] Estimate the average lifetime of the filament. What is the probability that we still have a polymer after that time if we were to perform an experiment of the exact same length? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stochastic model of gene expression\n",
    "\n",
    "In this problem, we will consider a very simplistic model of gene expression: \n",
    "DNA $\\rightarrow$ mRNA $\\rightarrow$ proteins. We will generate typical trajectories in the biomolecular phase space, generating the typical number of mRNAs and proteins that would be obtained starting from DNA that is transcribed and translated. \n",
    "The time evolution of the system is governed by the following equations: \n",
    "\\begin{equation}\n",
    "\\frac{dm}{dt} = \\beta_m - \\gamma_mm\\\\\n",
    "\\frac{dp}{dt} = \\beta_pm - \\gamma p\\\\\n",
    "\\end{equation}\n",
    "Here, $m$ and $p$ are the concentrations of mRNA and proteins, respectively; $\\beta_m$ the rate at which DNA is transcribed; $\\beta_p$ the rate at which mRNA is translated; $\\gamma_m$ and $\\gamma$ the degradation rates of mRNA and proteins. \n",
    "\n",
    "For convenience, we will work in reduced units of time, i.e., we set up the timescale to be that of mRNA degradation ($t$ replaces $\\gamma_mt$), and we then replace the different parameters by reduced ones: $\\beta_m \\equiv \\beta_m/\\gamma_m$, $\\beta_p \\equiv \\beta_p/\\gamma_m$, $\\gamma \\equiv \\gamma/\\gamma_m$. The dimensionless equations thus become\n",
    "\\begin{equation}\n",
    "\\frac{dm}{dt} = \\beta_m - m\\\\\n",
    "\\frac{dp}{dt} = \\beta_pm - \\gamma p\\\\\n",
    "\\end{equation}\n",
    "\n",
    "We can then write a Master equation for this dynamics, by introducing $P(m,p,t)$ the probability of having $m$ mRNA and $p$ proteins at time $t$. \n",
    "\\begin{equation}\n",
    "\\frac{dP(m,p,t)}{dt} = \\beta_mP(m-1,p,t) + (m+1)P(m+1,p,t) - \\beta_mP(m,p,t)-mP(m,p,t) + \\beta_pmP(m,p-1,t)+\\gamma(p+1)P(m,p+1,t) - \\beta_pmP(m,p,t) - \\gamma pP(m,p,t)\\\\\n",
    "\\end{equation}\n",
    "\n",
    "The Gillespie algorithm (proposed in the 70s), written below, is a way to solve this equation by sampling the trajectory space. You do not need to understand all the details, and you can find some useful documentation about it online if you are interested. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_update = np.array([[1, 0],   # Make mRNA transcript\n",
    "                          [-1, 0],  # Degrade mRNA\n",
    "                          [0, 1],   # Make protein\n",
    "                          [0, -1]], # Degrade protein\n",
    "                         dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_propensity(propensities, population, t, beta_m, beta_p, gamma):\n",
    "    \"\"\"Updates an array of propensities given a set of parameters\n",
    "    and an array of populations.\n",
    "    \"\"\"\n",
    "    # Unpack population\n",
    "    m, p = population\n",
    "    \n",
    "    # Update propensities\n",
    "    propensities[0] = beta_m      # Make mRNA transcript\n",
    "    propensities[1] = m           # Degrade mRNA\n",
    "    propensities[2] = beta_p * m  # Make protein\n",
    "    propensities[3] = gamma * p   # Degrade protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_discrete(probs):\n",
    "    \"\"\"Randomly sample an index with probability given by probs.\"\"\"\n",
    "    # Generate random number\n",
    "    q = np.random.rand()\n",
    "    \n",
    "    # Find index\n",
    "    i = 0\n",
    "    p_sum = 0.0\n",
    "    while p_sum < q:\n",
    "        p_sum += probs[i]\n",
    "        i += 1\n",
    "    return i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie_draw(propensity_func, propensities, population, t, args=()):\n",
    "    \"\"\"\n",
    "    Draws a reaction and the time it took to do that reaction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function with call signature propensity_func(population, t, *args)\n",
    "        used for computing propensities. This function must return\n",
    "        an array of propensities.\n",
    "    population : ndarray\n",
    "        Current population of particles\n",
    "    t : float\n",
    "        Value of the current time.\n",
    "    args : tuple, default ()\n",
    "        Arguments to be passed to `propensity_func`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    rxn : int\n",
    "        Index of reaction that occured.\n",
    "    time : float\n",
    "        Time it took for the reaction to occur.\n",
    "    \"\"\"\n",
    "    # Compute propensities\n",
    "    propensity_func(propensities, population, t, *args)\n",
    "    \n",
    "    # Sum of propensities\n",
    "    props_sum = propensities.sum()\n",
    "    \n",
    "    # Compute next time\n",
    "    time = np.random.exponential(1.0 / props_sum)\n",
    "    \n",
    "    # Compute discrete probabilities of each reaction\n",
    "    rxn_probs = propensities / props_sum\n",
    "    \n",
    "    # Draw reaction from this distribution\n",
    "    rxn = sample_discrete(rxn_probs)\n",
    "    \n",
    "    return rxn, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie_ssa(propensity_func, update, population_0, time_points, args=()):\n",
    "    \"\"\"\n",
    "    Uses the Gillespie stochastic simulation algorithm to sample\n",
    "    from probability distribution of particle counts over time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function of the form f(params, t, population) that takes the current\n",
    "        population of particle counts and return an array of propensities\n",
    "        for each reaction.\n",
    "    update : ndarray, shape (num_reactions, num_chemical_species)\n",
    "        Entry i, j gives the change in particle counts of species j\n",
    "        for chemical reaction i.\n",
    "    population_0 : array_like, shape (num_chemical_species)\n",
    "        Array of initial populations of all chemical species.\n",
    "    time_points : array_like, shape (num_time_points,)\n",
    "        Array of points in time for which to sample the probability\n",
    "        distribution.\n",
    "    args : tuple, default ()\n",
    "        The set of parameters to be passed to propensity_func.        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample : ndarray, shape (num_time_points, num_chemical_species)\n",
    "        Entry i, j is the count of chemical species j at time\n",
    "        time_points[i].\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize output\n",
    "    pop_out = np.empty((len(time_points), update.shape[1]), dtype=np.int)\n",
    "\n",
    "    # Initialize and perform simulation\n",
    "    i_time = 1\n",
    "    i = 0\n",
    "    t = time_points[0]\n",
    "    population = population_0.copy()\n",
    "    pop_out[0,:] = population\n",
    "    propensities = np.zeros(update.shape[0])\n",
    "    while i < len(time_points):\n",
    "        while t < time_points[i_time]:\n",
    "            # draw the event and time step\n",
    "            event, dt = gillespie_draw(propensity_func, propensities, population, t, args)\n",
    "                \n",
    "            # Update the population\n",
    "            population_previous = population.copy()\n",
    "            population += update[event,:]\n",
    "                \n",
    "            # Increment time\n",
    "            t += dt\n",
    "\n",
    "        # Update the index\n",
    "        i = np.searchsorted(time_points > t, True)\n",
    "        \n",
    "        # Update the population\n",
    "        pop_out[i_time:min(i,len(time_points))] = population_previous\n",
    "        \n",
    "        # Increment index\n",
    "        i_time = i\n",
    "                           \n",
    "    return pop_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the core of the algorithm. Now, let's see how it runs. \n",
    "With $args$, you pass the kinetic parameters  $\\beta_m, \\beta_p, \\gamma$ in reduced unites. $size$ is the number of trajectories that you want to sample, and $time\\_points$ will define the total simulation length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for calculation\n",
    "\n",
    "betam = 5.\n",
    "betap=5.\n",
    "gamma=2.\n",
    "\n",
    "tmax = 10 \n",
    "nbin = 101\n",
    "size = 2\n",
    "\n",
    "\n",
    "time_points = np.linspace(0, tmax, nbin)\n",
    "args = (betam, betap, gamma)\n",
    "\n",
    "\n",
    "population_0 = np.array([0, 0], dtype=int) # initial conditions \n",
    "\n",
    "\n",
    "# Seed random number generator for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize output array\n",
    "samples = np.empty((size, len(time_points), 2), dtype=int)\n",
    "\n",
    "# Run the calculations\n",
    "for i in tqdm.notebook.tqdm(range(size)):\n",
    "    samples[i,:,:] = gillespie_ssa(simple_propensity, simple_update,\n",
    "                                population_0, time_points, args=args)\n",
    "    \n",
    "# Solve the equations numerically \n",
    "\n",
    "# Plot trajectories and mean\n",
    "\n",
    "for x in samples[:,:,0]:\n",
    "    plt.plot(time_points, x, linewidth=0.3,alpha=0.8)\n",
    "plt.plot(time_points, samples[:,:,0].mean(axis=0),linewidth=2,alpha=1,color='red',label='m_avg(t)')\n",
    "#plt.plot(time_points, m,linewidth=2,alpha=1,color='blue',label='m_ODE(t)')\n",
    "plt.ylabel('mRNA')\n",
    "plt.xlabel('time')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "    \n",
    "for x in samples[:,:,1]:\n",
    "    plt.plot(time_points, x, linewidth=0.3,alpha=0.8)\n",
    "plt.plot(time_points, samples[:,:,1].mean(axis=0),linewidth=2,alpha=1,color='red',label='p_avg(t)')\n",
    "#plt.plot(time_points, p,linewidth=2,alpha=1,color='blue',label='m_ODE(t)')\n",
    "plt.ylabel('proteins')\n",
    "plt.xlabel('time')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Play with the number of sampled trajectories. How many are required to obtain some converged and smooth time-dependent populations?\n",
    "\n",
    "(2) The populations reach a plateau after an initial increase. Was this plateau expected? How is this related to $\\beta_m$, $\\beta_p$ and $\\gamma$?\n",
    "\n",
    "(3) In fact, the results of these stochastic simulations can be compared with the analytical solutions of the ordinary differential equations (ODE) defining the time evolution of the populations. The following piece of code returns m(t) and p(t) by solving these equations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns dz/dt\n",
    "def model(z,t):\n",
    "    m = z[0]\n",
    "    p = z[1]\n",
    "    dmdt = betam-m\n",
    "    dpdt = betap*m-gamma*p\n",
    "    dzdt = [dmdt,dpdt]\n",
    "    return dzdt\n",
    "\n",
    "# initial condition\n",
    "z0 = [0,0]\n",
    "# number of time points\n",
    "n = 101\n",
    "# time points\n",
    "t = np.linspace(0,10,n)\n",
    "# store solution\n",
    "m = np.empty_like(t)\n",
    "p = np.empty_like(t)\n",
    "# record initial conditions\n",
    "m[0] = z0[0]\n",
    "p[0] = z0[1]\n",
    "# solve ODE\n",
    "for i in range(1,n):\n",
    "    # span for next time step\n",
    "    tspan = [t[i-1],t[i]]\n",
    "    # solve for next step\n",
    "    z = odeint(model,z0,tspan)\n",
    "    # store solution for plotting\n",
    "    m[i] = z[1][0]\n",
    "    p[i] = z[1][1]\n",
    "    # next initial condition\n",
    "    z0 = z[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Re-run the cell propagating the algorithm by integrating this function and compare directly in the plots your results to that of the numerical results of the ODE. \n",
    "\n",
    "It is also possible to estimate the standard deviations, which will basically give an idea about the spread in the number of mRNA/proteins you would measure experimentally from a finite number of observations on a limited number of mRNA and protein copies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mRNA mean copy number =', samples[:,-50:,0].mean())\n",
    "print('protein mean copy number =', samples[:,-50:,1].mean())\n",
    "print('\\nmRNA standard deviation =', samples[:,-50:,0].std())\n",
    "print('protein standard deviation =', samples[:,-50:,1].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach can thus give some useful information about the probability distributions and about the likelihood of experimental observations, that continuous approaches such as the ODE do not give.\n",
    "\n",
    "(5) You can play around with the kinetic parameters to realize how they influence en time evolution of the populations, and how they determine e.g. their steady-state values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rate of barrier crossing\n",
    "\n",
    "In this problem, we will be running a Langevin dynamics code in order to simulate the diffusion of a model system on a model free-energy surface. Provided with the time-course of the particle position, we will then try to recover the rate at which it crosses the barrier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first examine the free-energy surface we will consider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The double-well potential we will use.\n",
    "\n",
    "def double_well(x,Uo,a,C):\n",
    "    k=100000\n",
    "    xlim=3.9\n",
    "    V=0\n",
    "    dV=0\n",
    "    if x>xlim:\n",
    "        V=k*(x-xlim)**2\n",
    "        dV=2*k*(x-xlim)\n",
    "    if x<-xlim:\n",
    "        V=k*(x+xlim)**2\n",
    "        dV=2*k*(x+xlim)\n",
    "    potential_energy=(Uo/a**4)*(C*x**2-a**2)**2 + V\n",
    "    return potential_energy\n",
    "\n",
    "Uo=15000.\n",
    "a=4\n",
    "C=2.\n",
    "L=8.\n",
    "xs=np.arange(-L/2,L/2,0.001)\n",
    "U=np.array([double_well(x,Uo,a,C) for x in xs])\n",
    "print(\"Barrier Height = \",U[4000] - np.min(U),  \" J/mol\")\n",
    "plt.figure()\n",
    "plt.plot(xs,U)\n",
    "plt.xlabel(\"x (Å)\")\n",
    "plt.ylabel(\"U (J/mol)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the algorithm itself and its subroutines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm BAOAB adapted from B Leimkuhler, C Matthews JCP 2013\n",
    "\n",
    "#Mass in kg/mol, energy in J/mol, T in K, length in Angstrom, time in ps.\n",
    "def position_update(x,v,dt):\n",
    "    x_new = x + v*dt/2.\n",
    "    return x_new\n",
    "\n",
    "def velocity_update(v,F,M,dt):\n",
    "    v_new = v + (F/M)*dt/2.\n",
    "    return v_new\n",
    "\n",
    "def random_velocity_update(v,gamma,T,M,R,dt):\n",
    "    xi = np.random.normal()\n",
    "    c1 = np.exp(-gamma*dt)\n",
    "    c2 = np.sqrt(1-c1*c1)*np.sqrt(R*T/M)\n",
    "    v_new = c1*v + xi*c2\n",
    "    return v_new\n",
    "\n",
    "def potential(x,Uo,a,C):\n",
    "    k=100000\n",
    "    xlim=3.9\n",
    "    V=0\n",
    "    dV=0\n",
    "    if x>xlim:\n",
    "        V=k*(x-xlim)**2\n",
    "        dV=2*k*(x-xlim)\n",
    "    if x<-xlim:\n",
    "        V=k*(x+xlim)**2\n",
    "        dV=2*k*(x+xlim)\n",
    "    potential_energy=(Uo/a**4)*(C*x**2-a**2)**2 + V\n",
    "    forc = -((4*Uo*C*x)/(a**4))*(C*x**2-a**2) + dV\n",
    "    return potential_energy,forc\n",
    "\n",
    "\n",
    "def position_pbc(x,L):\n",
    "    x_new=x\n",
    "    if (x>L/2.):\n",
    "        x_new=x-L\n",
    "    elif (x<-1*L/2.):\n",
    "        x_new=x+L\n",
    "    return x_new\n",
    "\n",
    "def baoab(L,max_time,dt,R,M,T,d,gamma,Uo,a,C,initial_position,initial_velocity,save_frequency=10, **kwargs ):\n",
    "    x = initial_position\n",
    "    v = initial_velocity\n",
    "    force=0.\n",
    "    t = 0\n",
    "    step_number = 0\n",
    "    positions = []\n",
    "    velocities = []\n",
    "    total_energies = []\n",
    "    save_times = []\n",
    "\n",
    "    while(t<max_time):\n",
    "\n",
    "        # B\n",
    "        potential_energy, force = potential(x,Uo,a,C)\n",
    "        v = velocity_update(v,force,M,dt)\n",
    "\n",
    "        #A\n",
    "        x = position_update(x,v,dt)\n",
    "\n",
    "        #check PBC (wrap)\n",
    "        x=position_pbc(x,L)\n",
    "\n",
    "        #O\n",
    "        v = random_velocity_update(v,gamma,T,M,R,dt)\n",
    "        #A\n",
    "        x = position_update(x,v,dt)\n",
    "\n",
    "        #check PBC (wrap)\n",
    "        x=position_pbc(x,L)\n",
    "\n",
    "        # B\n",
    "        potential_energy, force = potential(x,Uo,a,C)\n",
    "        v = velocity_update(v,force,M,dt)\n",
    "\n",
    "        if step_number%save_frequency == 0 and step_number>0:\n",
    "            e_total = .5*v*v + potential_energy\n",
    "\n",
    "            positions.append(x)\n",
    "            velocities.append(v)\n",
    "            total_energies.append(e_total)\n",
    "            save_times.append(t)\n",
    "\n",
    "        t = t+dt\n",
    "        step_number = step_number + 1\n",
    "\n",
    "    return save_times, positions, velocities, total_energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run a Langevin dynamics trajectory per se. The different parameters are first declared, and the self-comments should be pretty explicit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_L = 8. #angstrom\n",
    "my_max_time=3000#ps\n",
    "my_dt = 0.002 #ps\n",
    "my_T = 300 #K\n",
    "my_M = 1 #kg/mol\n",
    "Na= 6.02214076*10**23 #mol^-1\n",
    "kB = 1.380649*10**(-23) #J/K\n",
    "h=6.63*10**(-34) #J.s\n",
    "my_m = my_M/Na #kg\n",
    "my_D = 0.2 #angstrom²/ps\n",
    "R = 8.314 #J.mol^-1.K^-1\n",
    "my_gamma = R*my_T/(my_D*my_M) #ps^-1 \n",
    "initial_position = 0.\n",
    "initial_velocity = 0.0\n",
    "save_times,positions,velocities,total_energies =  baoab(my_L,my_max_time,my_dt,R,my_M,my_T,my_D,my_gamma,Uo,a,C,initial_position,initial_velocity,save_frequency=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Given that the particle position is saved every 10 simulation timesteps, plot the position of the particle as a function of time during the first 200 ps of the simulation. The following cell contains an example that you need to complete: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmx= 10000\n",
    "print(\"Portion of the trajectory : we can see jumps between the two wells.\")\n",
    "plt.figure()\n",
    "plt.plot(save_times[0:xmx],positions[0:xmx])\n",
    "plt.xlabel(\"Time (ps)\")\n",
    "plt.ylabel(\"x (Å)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) What kind of distribution do you expect for the particle positions? The following routine allows to perform such calculations; comment and proceed to the necessary changes to your simulation in order to recover results that follow your expectations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob,bins = np.histogram(positions,bins = 100,density=True)\n",
    "rplot=0.5*(bins[1:]+bins[:-1])\n",
    "plt.figure()\n",
    "plt.plot(rplot,prob)\n",
    "plt.xlabel(\"x (Å)\")\n",
    "plt.ylabel(\"Probability of presence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now estimate the rate of transition from the left well to the right well. We define state A as any system belonging to the left well. The following routine allows to compute the time correlation for being in A, using absorbing boundary conditions once the barrier to B has been crossed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability to be in A at an instant t:\n",
    "nt = len(positions)\n",
    "p_A = []\n",
    "for t in range(nt):\n",
    "    if positions[t]<-0.5:\n",
    "        p_A.append(1)\n",
    "    else:\n",
    "        p_A.append(0)\n",
    "p_A=np.array(p_A)\n",
    "\n",
    "corr_p = [] #A list of correlation functions (one per instant where the particule is in A)\n",
    "t_in_A = np.where(p_A==1)[0]  #look for the instant where the particule is in A\n",
    "for t in t_in_A: #compute the correlation function starting at every instant the particule is in A\n",
    "    if (t%10==0):\n",
    "        corr = []\n",
    "        tau=0\n",
    "        while ((t+tau<nt-1) & (p_A[t]*p_A[t+tau]==1)): #stop following the particule if goes in B\n",
    "            corr.append(p_A[t]*p_A[t+tau])\n",
    "            tau+=1\n",
    "        corr_p.append(corr)\n",
    "        \n",
    "        \n",
    "max_length = len(corr_p[0])\n",
    "for c in corr_p:\n",
    "    if len(c) > max_length:\n",
    "        max_length=len(c)\n",
    "        \n",
    "#Averaging the correlation functions on the starting points\n",
    "\n",
    "corr_p_avg = np.zeros(max_length)\n",
    "counts = np.zeros(max_length)\n",
    "for c in corr_p:\n",
    "    for j in range(len(c)):\n",
    "        corr_p_avg[j]+=1\n",
    "corr_p_avg/=(0.1*len(t_in_A))\n",
    "\n",
    "time_corr = np.array(save_times[0:max_length])\n",
    "plt.figure()\n",
    "plt.plot(time_corr,corr_p_avg)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('Time (ps)')\n",
    "plt.ylabel(\"C(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Comment on the decay of this correlation function. What does the time constant correspond to? How to compute the rate? \n",
    "\n",
    "This is done by the following routine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmx_fit = 300\n",
    "xmx_plot = -1\n",
    "from scipy.optimize import curve_fit\n",
    "def affine(x,a,b):\n",
    "    return a*x+b\n",
    "popt,pcov = curve_fit(affine,time_corr[0:xmx_fit],np.log(corr_p_avg[0:xmx_fit])) #we do an affine fit on the log of the correlation\n",
    "fv = np.exp(affine(time_corr[0:xmx_fit],popt[0],popt[1]))\n",
    "plt.figure()\n",
    "plt.plot(time_corr[0:xmx_plot],corr_p_avg[0:xmx_plot],label = \"Simulation\")\n",
    "plt.plot(time_corr[0:xmx_fit],fv,label = \"Exponential fit\",ls=\"dashed\")\n",
    "plt.xlabel(\"Time (ps)\")\n",
    "plt.ylabel(r\"$\\langle p_{A}(0)p_{A}(t)\\rangle$\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel('Time (ps)')\n",
    "plt.ylabel(\"C(t)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"k = \", -popt[0], \"ps-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) What is, in that case, the average lifetime in state A ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Does the result follow the expectations from the transition state theory? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) By systematically varying the free-energy barrier, investigate whether the rate constant is exponentially dependent on this barrier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
